lower.limit <- 0.00001

#' Row clustering using Ordered Stereotype Models or Proportional Odds Models.
#'
#' Users need to enter their chosen formula and model:
#' For Ordered Stereotype -- model = "OSM":
#' Y~row: Log(P(Y=k)/P(Y=1))=mu_k-phi_k*alpha_r
#' Y~row+column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_r+beta_j)
#' Y~row+column+row:column, or Y~row*column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k(alpha_r+beta_j+gamma_rj)
#' For Proportional Odds -- model = "POM":
#' Y~row: Logit=mu_k-alpha_r
#' Y~row+column: Logit=mu_k-alpha_r+beta_j
#' Y~row+column+row:column, or Y~row*column: Logit=mu_k-alpha_r+beta_j+gamma_rj
#' Users can select their own input parameters or starting values will be
#' generated by running kmeans or by fitting simpler models and feeding the outputs
#' into the final model as starting values.
#' @param formula: model formula.
#' @param model: "OSM" for Ordered Stereotype Model or "POM" for Proportional Odds Model.
#' @param nclus.row: number of row clustering groups.
#' @param long.df: data frame with at least three columns, Y and ROW and COL,
#'     where Y is the response variable, ROW is the factor to be clustered and
#'     COL is the additional factor included in the model. Typically, ROW will
#'     correspond to the row index and COL to the column index of an original
#'     data matrix whose values are given by Y.
#' @param initvect: (default NULL) vector of starting parameter values for the model.
#'     If NULL, starting parameter values will be generated automatically.
#'     q is the number of levels in the values of y, and p is the number of
#'     questions (or number of columns of y.mat)
#'     For OSM,
#'     starting values for mu are length q-1,
#'     starting values for phi are length q-2,
#'     starting values for alpha are length nclus.row-1
#'     starting values for beta (where applicable) are length p-1
#'     starting values for gamma (where applicable) are length (nclus.row-1)*(p-1)
#'     and the initvect for the different models is of the form:
#'     "Y~row" has initvect = c(mu, phi, alpha)
#'     "Y~row+column" has initvect = c(mu, phi, alpha, beta)
#'     "Y~row+column+row:column" or "Y~row*column" has initvect = c(mu, phi, alpha, beta, gamma)
#'     Note that the starting values for phi do not correspond directly to phi,
#'     because phi is restricted to being increasing and between 0 and 1, so
#'     instead the starting values are treated as elements u[2:q-1] of a vector
#'     u which can be between -Inf and +Inf, and then
#'     phi[2] <- expit(u[2]) and
#'     phi[k] <- expit(u[2] + sum(exp(u[3:k]))) for k between 3 and q-1
#'     (phi[1] = 0 and phi[q] = 1).
#'     For POM,
#'     use the same number of starting values as for OSM but exclude the phi components.
#'     Also note that the mu values in POM correspond to the first q-1 levels,
#'     whereas the mu values in OSM correspond to levels 2 to q, and mu_1 = 0.
#' @param pi.init: (default NULL) starting parameter values for the proportions
#'     of observations in the different row clusters.
#'     If NULL, starting values will be generated automatically.
#'     User-specified values of pi.init must be of length (nclus.row-1) because
#'     the final value will be automatically calculated so that the values of pi sum to 1.
#' @param EM.control: (default = list(EMcycles=50, EMstoppingpar=1e-4,
#'     paramstopping=TRUE, startEMcycles=10))
#'     list of parameters controlling the EM algorithm.
#'     `EMcycles` controls how many EM iterations of the main EM algorithm are
#'     used to fit the chosen submodel.
#'     `EMstoppingpar` is the tolerance for the stopping criteria in the EM algorithm.
#'     `paramstopping`: if FALSE, indicates that the EM algorithm should only
#'     check convergence based on the change in incomplete-data log-likelihood,
#'     relative to the current difference between the complete-data and
#'     incomplete-data log-likelihoods, i.e. abs(delta_lli)/abs(llc[iter] - lli[iter]);
#'     if TRUE, indicates that as well as checking the likelihood criterion, the
#'     EM algorithm should also check whether the relative change in the
#'     exponentials of the absolute values of the current parameters is below
#'     the tolerance `EMstoppingpar`, to see whether the parameters and the
#'     likelihood have both converged.
#'     `startEMcycles` controls how many EM iterations are used when fitting the
#'     simpler submodels to get starting values for fitting models with interaction.
#' @param optim.method: (default "L-BFGS-B") method to use in optim within the M
#'     step of the EM algorithm. Must be one of 'L-BFGS-B', 'BFGS', 'CG' or
#'     'Nelder-Mead' (i.e. not the SANN method).
#' @param optim.control control list for the `optim` call within the M step of the
#'     EM algorithm. See the control list Details in the `optim` manual for more info.
#' @param constraint.sum.zero (default TRUE) if true, use constraints that alpha
#'     sums to zero and beta sums to zero; if false, use constraints alpha_1=0
#'     and beta_1 = 0. Both versions have the final column of gamma equal to the
#'     negative sum of the other columns (so gamma columns sum to zero) and first
#'     row of gamma equal to the negative sum of the other rows (so gamma rows
#'     sum to zero).
#' @param use.alternative.start: (default TRUE) if true, fit the model
#'     without interactions first and use that to provide starting values of ppr.m
#'     and pi.v for fitting the model with interactions; if false, use the polr
#'     function and then the simple model, and then the model without
#'     interactions, to find starting values for fitting the model with interactions.
#' @return fitted values of parameters `pi` and `theta`, and fitted values of mu,
#'     phi, alpha, beta and gamma, as applicable, contained within `parlist.out`,
#'     as well as `ppr`, the posterior probabilities of membership of the row clusters,
#'     and `RowClusters`, the assigned row clusters based on maximum posterior probability.
#' @examples
#' rowclustering("Y~row",model="OSM",3,long.df),indicates model Log(P(Y=k)/P(Y=1))=mu_k-phi_k*alpha_r with 3 row clustering groups
#' rowclustering("Y~row+column",model="OSM",3,long.df),indicates model Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_r+beta_j) with 3 row clustering groups
#' rowclustering("Y~row+column+row:column",model="POM",2,long.df),indicates model Logit=mu_k-alpha_r-beta_j-gamma_rj with 2 row clustering groups
#' @export
rowclustering <- function(formula,
                          model,
                          nclus.row,
                          long.df,
                          initvect=NULL,
                          pi.init=NULL,
                          EM.control=list(EMcycles=50, EMstoppingpar=1e-4,
                                          paramstopping=TRUE, startEMcycles=10),
                          optim.method="L-BFGS-B", optim.control=default.optim.control(),
                          constraint.sum.zero=TRUE, use.alternative.start=TRUE){

    validate.inputs(type="row",
                    formula=formula, model=model, nclus.row=nclus.row,
                    long.df=long.df, initvect=initvect, pi.init=pi.init,
                    EM.control=EM.control, optim.method=optim.method,
                    constraint.sum.zero=constraint.sum.zero,
                    use.alternative.start=use.alternative.start)

    ## If ROW and COL are factors, convert them to their numeric values before
    ## running clustering
    long.df <- check.factors(long.df)

    ## Replace defaults with user-provided values, so that any control parameters
    ## the user did not specify are not left blank:
    default.EM.control <- as.list(args(rowclustering))$EM.control
    EM.control <- replacedefaults(default.EM.control, EM.control)

    submodel <- switch(formula,
                       "Y~row"="rs",
                       "Y~row+column"="rp",
                       "Y~row+column+row:column"="rpi",
                       "Y~row*column"="rpi",
                       stop('Error in formula'))

    print(paste("EM algorithm for",model))

    RG <- nclus.row

    if (is.null(initvect) | is.null(pi.init)) {
        ## generate.start will keep using whichever of initvect and pi.init is not null
        start.par <- generate.start.rowcluster(long.df, model=model, submodel=submodel, RG=RG,
                                               initvect=initvect, pi.init=pi.init,
                                               EM.control=EM.control,
                                               optim.method=optim.method,
                                               optim.control=optim.control,
                                               constraint.sum.zero=constraint.sum.zero,
                                               use.alternative.start=use.alternative.start)
        initvect <- start.par$initvect
        pi.init <- start.par$pi.init
    }

    run.EM.rowcluster(invect=initvect, long.df=long.df, model=model, submodel=submodel,
                      pi.v=pi.init, constraint.sum.zero=constraint.sum.zero,
                      EM.control=EM.control,
                      optim.method=optim.method, optim.control=optim.control)
}

#' Column clustering using Ordered Stereotype Models or Proportional Odds Models.
#'
#' Users need to enter their chosen formula and model:
#' For Ordered Stereotype -- model = "OSM":
#' Y~column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k*beta_c
#' Y~row+column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_i+beta_c)
#' Y~row+column+row:column, or Y~row*column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k(alpha_i+beta_c+gamma_ic)
#' For Proportional Odds -- model = "POM":
#' Y~row: Logit=mu_k-beta_c
#' Y~row+column: Logit=mu_k-alpha_i+beta_c
#' Y~row+column+row:column, or Y~row*column: Logit=mu_k-alpha_i+beta_c+gamma_ic
#' Users can select their own input parameters or starting values will be
#' generated by running kmeans or by fitting simpler models and feeding the outputs
#' into the final model as starting values.
#' @param formula: model formula.
#' @param model: "OSM" for Ordered Stereotype Model or "POM" for Proportional Odds Model.
#' @param nclus.column: number of column clustering groups.
#' @param long.df: data frame with at least three columns, Y and ROW and COL,
#'     where Y is the response variable, ROW is the factor to be clustered and
#'     COL is the additional factor included in the model. Typically, ROW will
#'     correspond to the row index and COL to the column index of an original
#'     data matrix whose values are given by Y.
#' @param initvect: (default NULL) vector of starting parameter values for the model.
#'     If NULL, starting parameter values will be generated automatically.
#'     q is the number of levels in the values of y, and n is the number of
#'     subjects (or number of rows of y.mat)
#'     For OSM,
#'     starting values for mu are length q-1,
#'     starting values for phi are length q-2,
#'     starting values for beta are length nclus.column-1
#'     starting values for alpha (where applicable) are length n-1
#'     starting values for gamma (where applicable) are length (n-1)*(nclus.column-1)
#'     and the initvect for the different models is of the form:
#'     "Y~row" has initvect = c(mu, phi, beta)
#'     "Y~row+column" has initvect = c(mu, phi, beta, alpha)
#'     "Y~row+column+row:column" or "Y~row*column" has initvect = c(mu, phi, beta, alpha, gamma)
#'     Note that the starting values for phi do not correspond directly to phi,
#'     because phi is restricted to being increasing and between 0 and 1, so
#'     instead the starting values are treated as elements u[2:q-1] of a vector
#'     u which can be between -Inf and +Inf, and then
#'     phi[2] <- expit(u[2]) and
#'     phi[k] <- expit(u[2] + sum(exp(u[3:k]))) for k between 3 and q-1
#'     (phi[1] = 0 and phi[q] = 1).
#'     For POM,
#'     use the same number of starting values as for OSM but exclude the phi components.
#'     Also note that the mu values in POM correspond to the first q-1 levels,
#'     whereas the mu values in OSM correspond to levels 2 to q, and mu_1 = 0.
#'     NOTE THAT THIS ORDERING OF INITVECT IS DIFFERENT THAN FOR ROW CLUSTERING OR
#'     BICLUSTERING.
#' @param kappa.init: (default NULL) starting parameter values for the proportions
#'     of observations in the different column clusters.
#'     If NULL, starting values will be generated automatically.
#'     User-specified values of pi.init must be of length (nclus.row-1) because
#'     the final value will be automatically calculated so that the values of pi sum to 1.
#' @param EM.control: (default = list(EMcycles=50, EMstoppingpar=1e-4,
#'     paramstopping=TRUE, startEMcycles=10))
#'     list of parameters controlling the EM algorithm.
#'     `EMcycles` controls how many EM iterations of the main EM algorithm are
#'     used to fit the chosen submodel.
#'     `EMstoppingpar` is the tolerance for the stopping criteria in the EM algorithm.
#'     `paramstopping`: if FALSE, indicates that the EM algorithm should only
#'     check convergence based on the change in incomplete-data log-likelihood,
#'     relative to the current difference between the complete-data and
#'     incomplete-data log-likelihoods, i.e. abs(delta_lli)/abs(llc[iter] - lli[iter]);
#'     if TRUE, indicates that as well as checking the likelihood criterion, the
#'     EM algorithm should also check whether the relative change in the
#'     exponentials of the absolute values of the current parameters is below
#'     the tolerance `EMstoppingpar`, to see whether the parameters and the
#'     likelihood have both converged.
#'     `startEMcycles` controls how many EM iterations are used when fitting the
#'     simpler submodels to get starting values for fitting models with interaction.
#' @param optim.method: (default "L-BFGS-B") method to use in optim within the M
#'     step of the EM algorithm. Must be one of 'L-BFGS-B', 'BFGS', 'CG' or
#'     'Nelder-Mead' (i.e. not the SANN method).
#' @param optim.control control list for the `optim` call within the M step of the
#'     EM algorithm. See the control list Details in the `optim` manual for more info.
#' @param constraint.sum.zero (default TRUE) if true, use constraints that alpha
#'     sums to zero and beta sums to zero; if false, use constraints alpha_1=0
#'     and beta_1 = 0. Both versions have the final column of gamma equal to the
#'     negative sum of the other columns (so gamma columns sum to zero) and first
#'     row of gamma equal to the negative sum of the other rows (so gamma rows
#'     sum to zero).
#' @param use.alternative.start: (default TRUE) if true, fit the model
#'     without interactions first and use that to provide starting values of ppr.m
#'     and pi.v for fitting the model with interactions; if false, use the polr
#'     function and then the simple model, and then the model without
#'     interactions, to find starting values for fitting the model with interactions.
#' @return fitted values of parameters `pi` and `theta`, and fitted values of mu,
#'     phi, alpha, beta and gamma, as applicable, contained within `parlist.out`,
#'     as well as `ppr`, the posterior probabilities of membership of the row clusters,
#'     and `RowClusters`, the assigned row clusters based on maximum posterior probability.
#' @examples
#' columnclustering("Y~column",model="OSM",3,long.df),indicates model Log(P(Y=k)/P(Y=1))=mu_k-phi_k*beta_c with 3 column clustering groups
#' columnclustering("Y~row+column",model="OSM",3,long.df),indicates model Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_i+beta_c) with 3 column clustering groups
#' columnclustering("Y~row+column+row:column",model="POM",2,long.df),indicates model Logit=mu_k-alpha_i-beta_c-gamma_ic with 2 column clustering groups
#' @export
columnclustering <- function(formula,
    model,
    nclus.column,
    long.df,
    initvect=NULL,
    kappa.init=NULL,
    EM.control=list(EMcycles=50, EMstoppingpar=1e-4, paramstopping=TRUE, startEMcycles=10),
    optim.method="L-BFGS-B", optim.control=default.optim.control(),
    constraint.sum.zero=TRUE, use.alternative.start=TRUE){

    validate.inputs(type="column",
                    formula=formula, model=model, nclus.column=nclus.column,
                    long.df=long.df, initvect=initvect, kappa.init=kappa.init,
                    EM.control=EM.control, optim.method=optim.method,
                    constraint.sum.zero=constraint.sum.zero,
                    use.alternative.start=use.alternative.start)

    ## If ROW and COL are factors, convert them to their numeric values before
    ## running clustering
    long.df <- check.factors(long.df)

    ## Replace defaults with user-provided values, so that any control parameters
    ## the user did not specify are not left blank:
    default.EM.control <- as.list(args(rowclustering))$EM.control
    EM.control <- replacedefaults(default.EM.control, EM.control)

    ## Now switch to calling everything in terms of row clustering
    submodel <- switch(formula,
        "Y~column"="rs",
        "Y~row+column"="rp",
        "Y~row+column+row:column"="rpi",
        "Y~row*column"="rpi",
        stop('Error in formula'))

    print(paste("EM algorithm for",model))

    RG <- nclus.column
    pi.init <- kappa.init
    long.df.transp <- long.df
    long.df.transp$ROW <- long.df$COL
    long.df.transp$COL <- long.df$ROW

    if (is.null(initvect) | is.null(pi.init)) {
        ## generate.start will keep using whichever of initvect and kappa.init is not null
        start.par <- generate.start.rowcluster(long.df.transp, model=model, submodel=submodel, RG=RG,
                                               initvect=initvect, pi.init=kappa.init,
                                               EM.control=EM.control,
                                               optim.method=optim.method,
                                               optim.control=optim.control,
                                               constraint.sum.zero=constraint.sum.zero,
                                               use.alternative.start=use.alternative.start)
        initvect <- start.par$initvect
        pi.init <- start.par$pi.init
    }

    results <- run.EM.rowcluster(invect=initvect, long.df=long.df.transp,
                                 model=model, submodel=submodel,
                                 pi.v=pi.init, constraint.sum.zero=constraint.sum.zero,
                                 EM.control=EM.control,
                                 optim.method=optim.method, optim.control=optim.control)

    ## Now convert the results back to row clustering
    column.parlist <- results$parlist.out
    column.parlist$beta <- results$parlist.out$alpha
    column.parlist$alpha <- NULL
    if (!is.null(results$parlist.out$beta)) column.parlist$alpha <- results$parlist.out$beta

    column.results <- list(info=results$info, EM.status=results$EM.status,
                           criteria=results$criteria,
                           initvect=initvect, parlist.out=column.parlist,
                           kappa=results$pi, ppc=results$ppr,
                            ColumnClusters=results$RowClusters)
    column.results$info['C'] <- column.results$info['R']
    column.results$info <- column.results$info[-which(names(column.results$info) == "R")]

    column.results
}

#' Biclustering using Ordered Stereotype Models or Proportional Odds Models.
#'
#' Users need to enter their chosen formula and model:
#' For Ordered Stereotype -- model = "OSM":
#' Y~row+column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_r+beta_c)
#' Y~row+column+row:column, or Y~row*column: Log(P(Y=k)/P(Y=1))=mu_k-phi_k(alpha_r+beta_c+gamma_rc)
#' For Proportional Odds -- model = "POM":
#' Y~row+column: Logit=mu_k-alpha_r+beta_c
#' Y~row+column+row:column, or Y~row*column: Logit=mu_k-alpha_r+beta_c+gamma_rc
#' NOTE the difference between these models and the ones for rowclustering: for
#' biclustering, the models involve column cluster effects instead of individual
#' column effects.
#' Users can select their own input parameters or starting values will be
#' generated by running kmeans or by fitting simpler models and feeding the outputs
#' into the final model as starting values.
#' @param formula: model formula.
#' @param model: "OSM" for Ordered Stereotype Model or "POM" for Proportional Odds Model.
#' @param nclus.row: number of row clustering groups.
#' @param nclus.column: number of column clustering groups.
#' @param long.df: data frame with at least three columns, Y and ROW and COL,
#'     where Y is the response variable, ROW is the factor to be clustered and
#'     COL is the additional factor included in the model. Typically, ROW will
#'     correspond to the row index and COL to the column index of an original
#'     data matrix whose values are given by Y.
#' @param initvect: (default NULL) vector of starting parameter values for the model.
#'     If NULL, starting parameter values will be generated automatically.
#'     q is the number of levels in the values of y, and p is the number of
#'     questions (or number of columns of y.mat)
#'     For OSM,
#'     starting values for mu are length q-1,
#'     starting values for phi are length q-2,
#'     starting values for alpha are length nclus.row-1
#'     starting values for beta are length nclus.column-1
#'     starting values for gamma (where applicable) are length (nclus.row-1)*(nclus.column-1)
#'     and the initvect for the different models is of the form:
#'     "Y~row+column" has initvect = c(mu, phi, alpha, beta)
#'     "Y~row+column+row:column" or "Y~row*column" has initvect = c(mu, phi, alpha, beta, gamma)
#'     Note that the starting values for phi do not correspond directly to phi,
#'     because phi is restricted to being increasing and between 0 and 1, so
#'     instead the starting values are treated as elements u[2:q-1] of a vector
#'     u which can be between -Inf and +Inf, and then
#'     phi[2] <- expit(u[2]) and
#'     phi[k] <- expit(u[2] + sum(exp(u[3:k]))) for k between 3 and q-1
#'     (phi[1] = 0 and phi[q] = 1).
#'     For POM,
#'     use the same number of starting values as for OSM but exclude the phi components.
#'     Also note that the mu values in POM correspond to the first q-1 levels,
#'     whereas the mu values in OSM correspond to levels 2 to q, and mu_1 = 0.
#' @param pi.init: (default NULL) starting parameter values for the proportions
#'     of observations in the different row clusters.
#'     If NULL, starting values will be generated automatically.
#'     User-specified values of pi.init must be of length (nclus.row-1) because
#'     the final value will be automatically calculated so that the values of pi sum to 1.
#' @param kappa.init: (default NULL) starting parameter values for the proportions
#'     of observations in the different column clusters.
#'     If NULL, starting values will be generated automatically.
#'     User-specified values of kappa.init must be of length (nclus.column-1) because
#'     the final value will be automatically calculated so that the values of kappa sum to 1.
#' @param EM.control: (default = list(EMcycles=50, EMstoppingpar=1e-4,
#'     paramstopping=TRUE, startEMcycles=10))
#'     list of parameters controlling the EM algorithm.
#'     `EMcycles` controls how many EM iterations of the main EM algorithm are
#'     used to fit the chosen submodel.
#'     `EMstoppingpar` is the tolerance for the stopping criteria in the EM algorithm.
#'     `paramstopping`: if FALSE, indicates that the EM algorithm should only
#'     check convergence based on the change in incomplete-data log-likelihood,
#'     relative to the current difference between the complete-data and
#'     incomplete-data log-likelihoods, i.e. abs(delta_lli)/abs(llc[iter] - lli[iter]);
#'     if TRUE, indicates that as well as checking the likelihood criterion, the
#'     EM algorithm should also check whether the relative change in the
#'     exponentials of the absolute values of the current parameters is below
#'     the tolerance `EMstoppingpar`, to see whether the parameters and the
#'     likelihood have both converged.
#'     `startEMcycles` controls how many EM iterations are used when fitting the
#'     simpler submodels to get starting values for fitting models with interaction.
#' @param optim.method: (default "L-BFGS-B") method to use in optim within the M
#'     step of the EM algorithm. Must be one of 'L-BFGS-B', 'BFGS', 'CG' or
#'     'Nelder-Mead' (i.e. not the SANN method).
#' @param optim.control control list for the `optim` call within the M step of the
#'     EM algorithm. See the control list Details in the `optim` manual for more info.
#' @param constraint.sum.zero (default TRUE) if true, use constraints that alpha
#'     sums to zero and beta sums to zero; if false, use constraints alpha_1=0
#'     and beta_1 = 0. Both versions have the final column of gamma equal to the
#'     negative sum of the other columns (so gamma columns sum to zero) and first
#'     row of gamma equal to the negative sum of the other rows (so gamma rows
#'     sum to zero).
#' @param use.alternative.start: (default TRUE) if true, fit the model
#'     without interactions first and use that to provide starting values of ppr.m
#'     and pi.v for fitting the model with interactions; if false, use the polr
#'     function and then the simple model, and then the model without
#'     interactions, to find starting values for fitting the model with interactions.
#' @return fitted values of parameters `pi`, `kappa` and `theta`, and fitted values
#'     of mu, phi, alpha, beta and gamma, as applicable, contained within `parlist.out`,
#'     as well as `ppr`, the posterior probabilities of membership of the row clusters,
#'     `RowClusters`, the assigned row clusters based on maximum posterior probability,
#'     `ppc`, the posterior probabilities of membership of the column clusters,
#'     and `ColumnClusters`, the assigned column clusters based on maximum
#'     posterior probability.
#' @examples
#' biclustering("Y~row+column",model="OSM",RG=3,CG=2,long.df),indicates model
#'     Log(P(Y=k)/P(Y=1))=mu_k-phi_k*(alpha_r+beta_c)
#'     with 3 row clustering groups and 2 column clustering groups.
#' biclustering("Y~row+column+row:column",model="POM",RG=2,CG=4,long.df),
#'     indicates model Logit=mu_k-alpha_r-beta_c-gamma_rc
#'     with 2 row clustering groups and 4 column clustering groups.
#' @export
biclustering <- function(formula,
    model,
    nclus.row,
    nclus.column,
    long.df,
    initvect=NULL,
    pi.init=NULL,
    kappa.init=NULL,
    EM.control=list(EMcycles=50, EMstoppingpar=1e-4, paramstopping=TRUE, startEMcycles=10),
    optim.method="L-BFGS-B", optim.control=default.optim.control(),
    constraint.sum.zero=TRUE,
    use.alternative.start=TRUE){

    validate.inputs(type="bi",
                    formula=formula, model=model,
                    nclus.row=nclus.row, nclus.column=nclus.column,
                    long.df=long.df, initvect=initvect,
                    pi.init=pi.init, kappa.init=kappa.init,
                    EM.control=EM.control, optim.method=optim.method,
                    constraint.sum.zero=constraint.sum.zero,
                    use.alternative.start=use.alternative.start)

    ## If ROW and COL are factors, convert them to their numeric values before
    ## running clustering
    long.df <- check.factors(long.df)

    ## Replace defaults with user-provided values, so that any control parameters
    ## the user did not specify are not left blank:
    default.EM.control <- as.list(args(rowclustering))$EM.control
    EM.control <- replacedefaults(default.EM.control, EM.control)

    submodel <- switch(formula,
        "Y~row+column"="rc",
        "Y~row+column+row:column"="rci",
        "Y~row*column"="rci",
        stop('Error in formula'))

    print(paste("EM algorithm for",model))

    RG <- nclus.row
    CG <- nclus.column

    if (is.null(initvect) | is.null(pi.init) | is.null(kappa.init)) {
        ## generate.start will keep using whichever of initvect and pi.init and
        ## kappa.init are not null
        start.par <- generate.start.bicluster(long.df, model=model, submodel=submodel,
                                              RG=RG, CG=CG, initvect=initvect,
                                              pi.init=pi.init, kappa.init=kappa.init,
                                              EM.control=EM.control,
                                              optim.method=optim.method,
                                              optim.control=optim.control,
                                              constraint.sum.zero=constraint.sum.zero,
                                              use.alternative.start=use.alternative.start)
        initvect <- start.par$initvect
        pi.init <- start.par$pi.init
        kappa.init <- start.par$kappa.init
    }

    run.EM.bicluster(invect=initvect, long.df=long.df, model=model, submodel=submodel,
        pi.v=pi.init, kappa.v=kappa.init, EM.control=EM.control,
        optim.method=optim.method, optim.control=optim.control)
}

default.optim.control <- function() {
    list(maxit=100,trace=0)
}

validate.inputs <- function(type,
                            formula,
                            model,
                            nclus.row=NULL,nclus.column=NULL,
                            long.df,
                            initvect=NULL,
                            pi.init=NULL, kappa.init=NULL,
                            EM.control=list(EMcycles=50, EMstoppingpar=1e-4, startEMcycles=10),
                            optim.method="L-BFGS-B",
                            constraint.sum.zero=TRUE, use.alternative.start=TRUE) {

    ## Note the double-& and double-| which stops the later parts being checked
    ## if the earlier parts are false

    if (!is.character(formula) || !is.vector(formula) || length(formula) != 1) stop("formula must be a string.")

    ## Check that model is valid
    if (!is.character(model) || !is.vector(model) || length(model) != 1) stop("model must be a string, either 'OSM' or 'POM'.")
    if (!(model %in% c("OSM","POM"))) stop("model must be either 'OSM' or POM' for the ordered stereotype and proportional odds models, respectively.")

    ## Check that clustering settings are valid
    if (type %in% c("row","bi") && is.null(nclus.row)) stop("For row clustering or biclustering, nclus.row cannot be null.")
    else if (!is.null(nclus.row)) {
        if (!is.vector(nclus.row) || length(nclus.row) != 1 || nclus.row <= 1 ||
            nclus.row %% 1 != 0 || is.na(nclus.row)) {
            stop("nclus.row must be an integer, from 2 to the number of rows/observations in the data.")
        }
    }
    if (type %in% c("column","bi") && is.null(nclus.column)) stop("For column clustering or biclustering, nclus.column cannot be null.")
    else if (!is.null(nclus.column)) {
        if (!is.vector(nclus.column) || length(nclus.column) != 1 ||
            nclus.column <= 1 || nclus.column %% 1 != 0 || is.na(nclus.column)) {
            stop("nclus.column must be an integer, from 2 to the number of columns/questions in the data.")
        }
    }

    if (is.null(long.df)) stop("long.df cannot be null.")
    if (!is.data.frame(long.df)) stop("long.df must be a data frame.")
    if (length(long.df) < 3) stop("long.df must have at least 3 columns, Y and ROW and COL.")
    if (!("Y" %in% names(long.df))) stop("long.df must have a column named 'Y' which contains the response values.")
    if (!("ROW" %in% names(long.df))) stop("long.df must have a column named 'ROW' which indicates what observation (row in the data matrix) each value of Y corresponds to.")
    if (!("COL" %in% names(long.df))) stop("long.df must have a column named 'COL' which indicates what variable (column in the data matrix) each value of Y corresponds to.")

    if (!is.factor(long.df$Y)) stop("long.df$Y must be a factor.")

    if (is.list(long.df$Y) || any(sapply(long.df$Y,is.list)) || any(is.na(long.df$Y)) ||
        any(sapply(long.df$Y,is.infinite))) stop("long.df$Y must be a factor with q levels.")
    if (!is.factor(long.df$ROW) &&
        (is.list(long.df$ROW) || any(sapply(long.df$ROW,is.list)) || any(is.na(long.df$ROW)) ||
        any(sapply(long.df$ROW,is.infinite)) || any(long.df$ROW %% 1 != 0) ||
        any(long.df$ROW < 1) || all(long.df$ROW > 1))) stop("long.df$ROW must be a factor or integers from 1 to the number of observations, i.e. the number of rows in the original data matrix.")
    if (!is.factor(long.df$COL) &&
        is.list(long.df$COL) || any(sapply(long.df$COL,is.list)) || any(is.na(long.df$COL)) ||
        any(sapply(long.df$COL,is.infinite)) || any(long.df$COL %% 1 != 0) ||
        any(long.df$COL < 1) || all(long.df$COL > 1)) stop("long.df$COL must be a factor or integers from 1 to the number of variables, i.e. the number of columns in the original data matrix.")

    if (!all(table(long.df[,c("ROW","COL")]) == 1)) stop("Each element from the original data matrix must correspond to exactly 1 row in long.df.")

    if (!is.null(nclus.row) && nclus.row >= max(as.numeric(long.df$ROW))) stop("nclus.row must be smaller than the maximum value of long.df$ROW.")
    if (!is.null(nclus.column) && nclus.column >= max(as.numeric(long.df$COL))) stop("nclus.column must be smaller than the maximum value of long.df$COL.")

    if (!is.null(initvect)) {
        if (!is.vector(initvect) || !is.numeric(initvect) || any(is.na(initvect)) ||
            any(is.infinite(initvect))) stop("If supplied, initvect must be a numeric vector with finite values.")
        if (length(initvect) > 20) stop("initvect is too long. Please check inputs and try again.")
    }

    if (!is.null(pi.init)) {
        if (!is.vector(pi.init) || !is.numeric(pi.init) || any(is.na(pi.init)) ||
            any(pi.init < 0) || any(pi.init > 1)) stop("If supplied, pi.init must be a vector of numbers between 0 and 1.")
        if (length(pi.init) != nclus.row || sum(pi.init) != 1) stop("pi.init must be the same length as the number of row clusters, and must add up to 1")
    }
    if (!is.null(kappa.init)) {
        if (!is.vector(kappa.init) || !is.numeric(kappa.init) || any(is.na(kappa.init)) ||
            any(kappa.init < 0) | any(kappa.init > 1)) stop("If supplied, kappa.init must be a vector of numbers between 0 and 1.")
        if (length(kappa.init) != nclus.column || sum(kappa.init) != 1) stop("kappa.init must be the same length as the number of column clusters, and must add up to 1")
    }

    if (!is.logical(constraint.sum.zero) || !is.vector(constraint.sum.zero) ||
        length(constraint.sum.zero) != 1 || is.na(constraint.sum.zero)) stop("constraint.sum.zero must be TRUE or FALSE.")
    if (!is.logical(use.alternative.start) || !is.vector(use.alternative.start) ||
        length(use.alternative.start) != 1 || is.na(use.alternative.start)) stop("use.alternative.start must be TRUE or FALSE.")

    if (!is.list(EM.control) || length(EM.control) == 0 || length(EM.control) > 4 ||
        !all(names(EM.control) %in% c("EMcycles","EMstoppingpar","paramstopping","startEMcycles"))) {
        stop("If supplied, EM.control must be a list of control parameters for the EM algorithm. Please see the manual for more info.")
    }

    if (is.null(optim.method) || !is.character(optim.method) || !is.vector(optim.method) ||
        length(optim.method) != 1 || !(optim.method %in% c("Nelder-Mead","BFGS","CG","L-BFGS-B"))) stop("If supplied, optim.method must be one of the valid methods for optim, 'Nelder-Mead', 'CG', 'BFGS' or 'L-BFGS-B'.")
}

check.factors <- function(long.df) {
    if (is.factor(long.df$ROW)) {
        print("Converting factor ROW to numeric.")
        attributes(long.df)$ROWlevels <- levels(long.df$ROW)
        long.df$ROW <- as.numeric(long.df$ROW)
    }
    if (is.factor(long.df$COL)) {
        print("Converting factor COL to numeric")
        attributes(long.df)$COLlevels <- levels(long.df$COL)
        long.df$COL <- as.numeric(long.df$COL)
    }
    long.df
}

new.EM.status <- function() {
    list(iter=0,finished=FALSE,converged=FALSE, paramstopping=FALSE,
         llc.for.best.lli=-.Machine$double.xmax,best.lli=-.Machine$double.xmax,
         new.lli=-.Machine$double.xmax, previous.lli=-.Machine$double.xmax)
}

update.EM.status <- function(EM.status, new.llc, new.lli, invect, outvect, EM.control) {
    iter <- EM.status$iter+1
    finished <- FALSE
    converged <- FALSE

    if (new.lli > EM.status$best.lli) {
        best.lli <- new.lli
        llc.for.best.lli <- new.llc
    } else {
        best.lli <- EM.status$best.lli
        llc.for.best.lli <- EM.status$llc.for.best.lli
    }

    param.exp.in <- exp(abs(invect))
    param.exp.out <- exp(abs(outvect))
    param.stopping.criterion <- sum(abs(param.exp.in - param.exp.out)/param.exp.out)

    ## Check difference between llc and lli to avoid divide-by-zero error in
    ## stopping criterion
    if (abs(new.llc - new.lli) < 1E-10) new.llc <- new.lli + 1E-10
    likelihood.stopping.criterion <- abs(EM.status$previous.lli - new.lli)/abs(new.llc - new.lli)

    if (likelihood.stopping.criterion < EM.control$EMstoppingpar &
        (!EM.control$paramstopping || param.stopping.criterion < EM.control$EMstoppingpar)) converged <- TRUE

    if (converged || iter >= EM.control$EMcycles) finished <- TRUE
    list(iter=iter,finished=finished,converged=converged,
         new.llc=new.llc, new.lli=new.lli, previous.lli=EM.status$new.lli,
         llc.for.best.lli=llc.for.best.lli, best.lli=best.lli,
         paramstopping=EM.control$paramstopping)
}

run.EM.rowcluster <- function(invect, long.df, model, submodel, pi.v,
                              constraint.sum.zero=TRUE,
                              EM.control=list(EMcycles=50, EMstoppingpar=1e-4, startEMcycles=10),
                              optim.method="L-BFGS-B", optim.control=default.optim.control()) {
    n <- max(long.df$ROW)
    p <- max(long.df$COL)
    q <- length(levels(long.df$Y))
    RG <- length(pi.v)

    parlist.in <- unpack.parvec(invect,model=model,submodel=submodel,n=n,p=p,q=q,RG=RG,
                                constraint.sum.zero=constraint.sum.zero)
    if (any(sapply(parlist.in,function(elt) any(is.na(elt))))) stop("Error unpacking parameters for model.")
    if (any(sapply(parlist.in,function(elt) is.null(elt)))) stop("Error unpacking parameters for model.")

    theta.arr <- calc.theta(parlist.in,model=model,submodel=submodel)

    y.mat <- df2mat(long.df)

    parlist.init <- parlist.in
    initvect <- invect
    outvect=invect
    # Run the EM cycle:
    EM.status <- new.EM.status()

    while(!EM.status$finished)
    {
        # E-step - Update posterior probabilities
        ppr.m <- onemode.membership.pp(long.df, theta.arr, pi.v, n, row=TRUE)

        ## Now set any NA values in the posterior probabilities matrix to 0
        ppr.m[is.na(ppr.m)] <- 0

        pi.v <- colMeans(ppr.m)

        invect=outvect
        # M-step:
        #use numerical maximisation
        optim.fit <- optim(par=invect,
                           fn=calc.ll,
                           long.df=long.df,
                           y.mat=y.mat,
                           model=model,
                           submodel=submodel,
                           ppr.m=ppr.m,
                           pi.v=pi.v,
                           RG=RG,
                           constraint.sum.zero=constraint.sum.zero,
                           partial=TRUE,
                           method=optim.method,
                           hessian=F,control=optim.control)

        outvect <- optim.fit$par
        llc <- -calc.ll(outvect,long.df=long.df,y.mat=y.mat,model=model,submodel=submodel,
                        ppr.m,pi.v,RG, partial=FALSE)

        parlist.out <- unpack.parvec(outvect,model=model,submodel=submodel,n=n,p=p,q=q,RG=RG,
                                     constraint.sum.zero=constraint.sum.zero)
        theta.arr <- calc.theta(parlist.out,model=model,submodel=submodel)

        ## Note that UNLIKE Rcluster.ll, Rcluster.Incll outputs the *actual*
        ## log-likelihood, not the negative of the log-likelihood, so don't need
        ## to make it negative here
        lli <- Rcluster.Incll(long.df, theta.arr, pi.v, RG)

        EM.status <- update.EM.status(EM.status,new.llc=llc,new.lli=lli,
                                     invect=invect,outvect=outvect,EM.control=EM.control)

        ## Report the current incomplete-data log-likelihood, which is the
        ## NEGATIVE of the latest value of Rcluster.ll i.e. the NEGATIVE
        ## of the output of optim
        # if (iter == 1 | iter%%5 == 0) cat(paste(toupper(submodel),'model iter=',iter, ' log.like=', llc ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' partial complete-data log.like=', -optim.fit$value ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' complete-data log.like=', llc ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' incomplete-data log.like=', lli ,'\n'))
        cat("parlist.out\n")
        print(parlist.out)
        cat("pi",pi.v,"\n")
    }

    # Find cluster groupings:
    Rclus <- assignments(ppr.m)

    # Save results:
    npar <- length(invect) + length(pi.v)-1
    criteria <- calc.criteria(lli, llc, npar, n, p)
    info <- c(n, p, npar, RG)
    names(info) <- c("n","p","npar","R")
    list("info"=info,
         "EM.status"=EM.status,
         "criteria"=criteria,
         "constraint.sum.zero"=constraint.sum.zero,
         "initvect"=initvect,
         "parlist.init"=parlist.init,
         "parlist.out"=parlist.out,
         "pi"=pi.v,
         "ppr"=ppr.m,
         "RowClusters"=Rclus)
}

run.EM.bicluster <- function(invect, long.df, model, submodel, pi.v, kappa.v,
                             constraint.sum.zero=TRUE,
                             EM.control=list(EMcycles=50, EMstoppingpar=1e-4, startEMcycles=10),
                             optim.method="L-BFGS-B", optim.control=default.optim.control()) {
    n <- max(long.df$ROW)
    p <- max(long.df$COL)
    q <- length(levels(long.df$Y))
    RG <- length(pi.v)
    CG <- length(kappa.v)

    parlist.in <- unpack.parvec(invect,model=model,submodel=submodel,n=n,p=p,q=q,RG=RG,CG=CG,
                                constraint.sum.zero=constraint.sum.zero)
    if (any(sapply(parlist.in,function(elt) any(is.na(elt))))) stop("Error unpacking parameters for model.")
    if (any(sapply(parlist.in,function(elt) is.null(elt)))) stop("Error unpacking parameters for model.")

    theta.arr <- calc.theta(parlist.in,model=model,submodel=submodel)

    y.mat <- df2mat(long.df)

    parlist.init <- parlist.in
    initvect <- invect
    outvect=invect
    # Run the EM cycle:
    EM.status <- new.EM.status()

    while(!EM.status$finished)
    {
        # E-step - Update posterior probabilities
        ppr.m <- twomode.membership.pp(long.df, theta.arr, pi.v, kappa.v, RG, row=TRUE)

        ## Now set any NA values in the posterior probabilities matrix to 0
        ppr.m[is.na(ppr.m)] <- 0

        pi.v <- colMeans(ppr.m)

        ppc.m <- twomode.membership.pp(long.df, theta.arr, pi.v, kappa.v, CG, row=FALSE)

        ## Now set any NA values in the posterior probabilities matrix to 0
        ppc.m[is.na(ppc.m)] <- 0

        kappa.v <- colMeans(ppc.m)

        invect=outvect
        # M-step:
        #use numerical maximisation
        optim.fit <- optim(par=invect,
            fn=calc.ll,
            long.df=long.df,
            y.mat=y.mat,
            model=model,
            submodel=submodel,
            ppr.m=ppr.m,
            pi.v=pi.v,
            RG=RG,
            ppc.m=ppc.m,
            kappa.v=kappa.v,
            CG=CG,
            constraint.sum.zero=constraint.sum.zero,
            partial=TRUE,
            method=optim.method,
            hessian=F,control=optim.control)

        outvect <- optim.fit$par

        llc <- -calc.ll(outvect,long.df=long.df,y.mat=y.mat,model=model,submodel=submodel,
            ppr.m=ppr.m,pi.v=pi.v,RG=RG, ppc.m=ppc.m,kappa.v=kappa.v,CG=CG,
            partial=FALSE)

        parlist.out <- unpack.parvec(outvect,model=model,submodel=submodel,
            n=n,p=p,q=q,RG=RG,CG=CG,constraint.sum.zero=constraint.sum.zero)
        theta.arr <- calc.theta(parlist.out,model=model,submodel=submodel)

        ## Note that UNLIKE Bicluster.ll, Bicluster.Incll outputs the *actual*
        ## log-likelihood, not the negative of the log-likelihood, so don't need
        ## to make it negative here
        if(CG^p<RG^n) lli <- Bicluster.IncllC(long.df, theta.arr, pi.v, kappa.v)
        else lli <- Bicluster.IncllR(long.df, theta.arr, pi.v, kappa.v)
if (is.na(lli)) browser()
        EM.status <- update.EM.status(EM.status,new.llc=llc,new.lli=lli,
                                     invect=invect,outvect=outvect,EM.control=EM.control)

        ## Report the current incomplete-data log-likelihood, which is the
        ## NEGATIVE of the latest value of Bicluster.ll i.e. the NEGATIVE
        ## of the output of optim
        # if (iter == 1 | iter%%5 == 0) cat(paste(toupper(submodel),'model iter=',iter, ' log.like=', llc ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' partial complete-data log.like=', -optim.fit$value ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' complete-data log.like=', llc ,'\n'))
        cat(paste(toupper(submodel),'model iter=',EM.status$iter, ' incomplete-data log.like=', lli ,'\n'))
        cat("parlist.out\n")
        print(parlist.out)
        cat("pi",pi.v,"\n")
        cat("kappa",kappa.v,"\n")
    }

    # Find cluster groupings:
    Rclus <- assignments(ppr.m)
    Cclus <- assignments(ppc.m)

    # Save results:
    npar <- length(invect) + length(pi.v)-1 + length(kappa.v)-1
    criteria <- calc.criteria(lli, llc, npar, n, p)
    info <- c(n, p, npar, RG, CG)
    names(info) <- c("n","p","npar","R","C")
    list("info"=info,
         "EM.status"=EM.status,
        "criteria"=criteria,
        "constraint.sum.zero"=constraint.sum.zero,
        "initvect"=initvect,
        "parlist.init"=parlist.init,
        "parlist.out"=parlist.out,
        "pi"=pi.v,
        "ppr"=ppr.m,
        "kappa"=kappa.v,
        "ppc"=ppc.m,
        "RowClusters"=Rclus,
        "ColClusters"=Cclus)
}